{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cf4895-94f2-4c02-894b-19c06577664b",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112c175-659b-43a4-8f3d-d5a581ce007c",
   "metadata": {},
   "source": [
    "In a recent notebook I tried to answer the Q. which image models are best? This showed which models in Ross Wightman's PyTorch Image Models(timm) were the fastest and most accurate for training from scratch with imagenet.\n",
    "\n",
    "However, this is not what most of us use models for. Most of us fine-tune pretrained models. Therefore, what most of us really want to know is which models are the fastest and most accurate for fine-tuning. However, this analysis has not, to my knowledge, previously existed.\n",
    "\n",
    "In this notebook, I present results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bd084-9829-437b-bf0d-c0644e868f9e",
   "metadata": {},
   "source": [
    "# Tha analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7f729-7956-449e-ac1c-41bfaf1cbeca",
   "metadata": {},
   "source": [
    "There are two key dimensions on which datasets can vary when it comes to how well they fine-tune a model:\n",
    "\n",
    "1. How similar they are to the pre-trained model's dataset.\n",
    "2. How large they are.\n",
    "\n",
    "Therefore, we decided to test on two datasets that were very different on both of these axes. We tested pre-trained models that were trained on Imagenet, and test fine-tuning on two different datasets:\n",
    "\n",
    "1. The [Oxford IIT-Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/), which is very similar to Imagenet. Imagenet contains many pictures of animals, and each picture is a photo in which the animal is the main subject. IIT-Pet contains nearly 15,000 images, that are also of this type.\n",
    "2. The [Kaggle Planet](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data) sample contains 1,000 satellite images of Earth. There are no images of this kind in Imagenet.\n",
    "\n",
    "So these two datasets are of very different sizes, and very different in terms of their similarity to Imagenet. Furthurmore, they have different types of labels - Planet is a multi-label problem, whereas IIT-Pet is a single label problem.\n",
    "\n",
    "To test the fine-tuning accuract of different models, Thomas put together [this script](https://github.com/tcapelle/fastai_timm/blob/main/fine_tune.py). The basic script contains the standard 4 lines of code needed for fastai image recognition models, plus some code to handle various configuration options, such as learning rate and batch size. It was particularly easy to handle in fastai since fastai supports all timm models directly.\n",
    "\n",
    "Then, to allow us to easily try different configuration options, Thomas created Weights and Biases(wandb) YAML files such as [this one](https://github.com/tcapelle/fastai_timm/blob/main/sweep_planets_lr.yaml). This takes advantage of the convinient [wandb \"sweeps\"](https://wandb.ai/site/sweeps) feature which tries a range of different levels of a model input and tracks the results.\n",
    "\n",
    "wandb makes it really easy for a group of people to run these kinds of analyses on whatever GPUs they have access to. When you create a sweep using the command-line wandb client, it gives you a command to run to have a computer run experiments for the project. You run that same command on each computer where you want to run experiments. The wandb client automatically ensures that each computer runs different parts of the sweep, and has each on report back its results to the wandb server. You can look at the progress in the wandb web GUI at any time during or after the run. I've got three GPUs in my PC at home, so I ran three copies of the client, with each using a different GPU. Thomas also ran the client on a [Paperspace Gradient](https://gradient.run/notebooks) server.\n",
    "\n",
    "I liked this approach because I could start and stop the clients any time I wanted, and wandb would automatically handle keeping all the results in sync. When I restarted a client, it would automatically grab from the server whatever the next set of sweep settings were needed. Furthermore, the integration in fastai is really exceptional, thanks particularly to Boris Dayma, who worked tirelessly to ensure that wandb automatically tracks every aspect of all fastai data processing, model architectures, and optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b2d76-b8ae-4687-be60-c016baf33e7d",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7be7f-9e50-4551-930d-0c6e89611c67",
   "metadata": {},
   "source": [
    "We decided to try out all the timm models which had reasonable performance on timm, and which are capable of working with 224x224 px images. We ended up with a list of 86 models and variants to try.\n",
    "\n",
    "Our first step was to find a good set of hyper-params for each model variant and for each dataset. Our experience at fast.ai has been that there's generally not much difference between models and datasets in terms of what hyperparam settings work well -- and that experience was repeated in this project. Based on some initial sweeps across a smaller number of representative models, on which we found little variation in optimal hyperparams, in our final sweep we included all combinations of the following options:\n",
    "\n",
    "- Learning rate(AdamW): 0.008 and 0.02\n",
    "- Resized method: Squish\n",
    "- Pooling type: Concat and Average Pooling\n",
    "\n",
    "For other params, we used defaults that we've previously found at fast.ai to be reliable across a range of models and datasets(see the fastai docs for details)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
